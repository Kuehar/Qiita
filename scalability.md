

スケーラビリティ

負荷の増大に対してシステムが対応できる能力を指す。
スケーラビリティについて議論をする時は、特定のシステムがスケールする/しないという話ではなく、「システムの特定の部分が成長した場合、どのような対応方法が存在するか？」という考慮を必要とする問いかけをすること。

負荷の表現

システムにおける負荷は負荷のパラメータと呼ばれる数値によって表現可能。

パラメータとしては、
Webサーバー→毎秒のリクエスト数
データベース→読み書きの比率
チャットルーム→同時アクティブユーザー数
キャッシュ→ヒット率
といった値が挙げられる。

パラメータを選択するときは一律にこのパラメータを使用する、ということではなく、何が最適かはシステムのアーキテクチャに依存する。

Twitterでは、サービスにかかる負荷として

ツイートのポスト
平均4600リクエスト/秒
ピーク時12000リクエスト/秒

タイムラインリクエスト
300000リクエスト/秒

という値が公開されていた。

毎秒12000回の書き込みに対応することは極めて容易。主な課題はファンアウトにある。
※ここでのファンアウトとはツイートのポストにより、他のユーザーのタイムラインに反映を行うこと。

これはTwitterなどのSNSに特有の、ユーザーが他のユーザーをフォローしたり、フォローされたりしているシステム構成によって生じる問題。

当初、Twitterは以下のような（あくまで簡易的な構成）RDBを用いたアプローチを取っていた。





しかし、タイムラインを取得するクエリの負荷が大きくなりすぎて、次第に上手く動かなくなっていった。

そこで新たにTwitterが取った方法として、あらかじめ各ユーザーのタイムラインをキャッシュしておき、ユーザーがツイートをポストしたタイミングでそのユーザーをフォローしているユーザーを検索し、該当するユーザーのタイムラインにツイートを差し込む、という手法。
先述の方法に比べてタイムラインの読み込み回数が2桁分少なく済んだ。


この方法のメリットとしては、ツイートのポスト時に発生するタイムラインの読み取りリクエストの結果は前もって生成されているため、必然的にポスト時の負荷が軽くなる、ということ。

一方で、フォロワー数の違いによって書き込み時間に大きな差が生まれる。
例えば、1億人のフォロワーがいるような有名人がツイートをポストした場合、1億回の書き込みがそのまま行われる、ということになる。

Twitterは新しくポストされたツイートを5秒以内に配信しようとしていたので、この点は無視できなかった。
そこで、最終的にTwitterは1つ目の方法と改善した2つ目の方法の二つを組み合わせた形式を採用した。

具体的には、フォロワーが一定数以上存在するユーザーに対しては1つ目の個別にクエリを発行する方法を採用し、それ以外のユーザーは2つ目の方法を採用することで対応した。

パフォーマンスの表現

システムの負荷について理解すれば、負荷が増大した時に起こることを調査可能になる。
以下の方法で調べることが可能。

・負荷のパラメータを増やしながらシステムのリソースは一定のままに保つとシステムのパフォーマンスにどういった影響をあたえるか？
・負荷のパラメータを増やした時にパフォーマンスを一定に保つにはリソースをどれだけ増やさなければならないか？
など。

Hadoopのようなバッチ処理システムの場合、一般的に注目するのはスループット。
ここでは1秒あたりに処理できるレコード数や、あるサイズのデータセットに対して1つのジョブを実行するのにかかる時間。

オンラインシステムの場合、クライアントがリクエストを送信してから返ってくるまでのレスポンスタイム。
ここでのレスポンスタイムはネットワーク、キューイングなどの遅延も含まれるため、リクエストが処理を待っている期間であるレイテンシーとは異なる。

この定義に基づくと、レスポンスタイムは基本的には毎回異なる値となる。
更に、システムはさまざまなリクエストを処理することを考慮すると、大きな幅が生じると考えられる。
故に、レスポンスタイムは計測可能な値の分布として考えるべき。

サービスのレスポンスタイムについては平均値を見ることが一般的だが、レスポンスタイムの平均値でサービスを分析しようとした場合、平均値から離れたユーザーがどれくらい存在しているかを把握できないため、そういった観点で分析する際には不向き。

より良い方法としては、中央値（50パーセンタイル値）などのパーセンタイルを使用する方法が考えられる。
こちらであれば、中央値が200msだった場合、クライアントからのリクエストの半分に対しては200ms以下でレスポンスが返されたことになり、もう半分には200ms以上の時間がかかったことになる。

なお、中央値で計測可能なものは単一のリクエストのみであることに注意をする。
これは、複数のリクエストを行っている場合には単一セッションの中で、あるいはページ内にいくつかのリソースが含まれているために、複数のリクエストのうち、少なくとも一つ以上が中央値よりも遅くなる確率が50%を大きく上回るものになるため。

より詳細にレスポンスタイムを分析する時には、95パーセンタイル値、99パーセンタイル値、99.9パーセンタイル値（それぞれp95,p99,p99.9と略されることがある）を見ると、外れ値がどれほど悪いかを分析できる。

例えば、Amazonでは内部的なサービスのレスポンスタイムに対する要件を99.9パーセンタイルで表している。これは1000件のリクエストが存在する場合、最もレスポンスタイムがかかっているリクエスト1件を指す。
Amazonがこのような厳格な基準を持っている理由としては、特に処理のかかっているリクエストを発行しているユーザーは大量の購入をし、アカウントに大量のデータを保持している可能性が高く、重要な顧客である可能性が高いため。
このユーザーの体験を向上させることは即ち売上の向上に直結することから重視されている。

大きなパーセンタイルのレスポンス値はキューイングの遅延によるものが多い。
サーバーが同時に並列処理できる数は少ない（CPUコア数で制限されたりする）ため、低速なリクエストが少し存在するだけで、その後のリクエストが待たされることになる。この現象はヘッドオブラインブロッキング（head-of-line blocking,HOLブロッキング）と呼ばれる。

これらの後続リクエストが高速に処理されたとしても、遅延した分、クライアントから見たリクエストタイムは大きくなる。その為、レスポンスタイムはクライアント側で計測することが重要。

負荷の対処へのアプローチ

仮に負荷が1桁増えた場合、アーキテクチャを考え直さなければならなくなることが多い。
その際、スケールアップ（垂直スケーリング、マシンのスペックを強化すること）かスケールアウト（水平スケーリング、複数のマシンに負荷を分散すること。シェアードナッシングアーキテクチャとも言う）を検討することになる。

スケールアップの方がシンプルではあるが、ハイエンドのマシンは高いという欠点がある。
スケールアウトで負荷に対応する場合には、システムがステートレスであるかが重要。仮にステートフルなシステムである場合は複雑性が大きく高まる可能性がある。
その為、近年まで負荷の増大時にもデータベースはスケールアップで対応することが一般的だった。

汎用的で、1つのサイズで全てのケースに対応できる（one-size-fits-all）スケーラブルなアーキテクチャは存在しない。（魔法のスケーリングソースというらしい。）
大規模なシステムであればあるほど、そのシステム固有の事象は多くなる。
アプリケーションを上手くスケールさせることができるアーキテクチャは、負荷のパラメータから構築される。初期の段階のスタートアップやプロダクトの検証段階の場合にはプロダクトの機能に関するイテレーションを素早く行える状態の方が重要。

